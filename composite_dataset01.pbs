#!/bin/bash
#LongQ will tell it to run on compute node
#PBS -q longq
# set name of job
#PBS -N composite_dataset 
#PBS -e /home/bwang/temp/logs/pbs/
#PBS -o /home/bwang/temp/logs/pbs/
# set the number of nodes and processes per node
#PBS -l nodes=1:ppn=40
#PBS -l mem=80Gb
# mail alert at (b)eginning, (e)nd and (a)bortion of execution
#PBS -m bea
# send mail to the following address
#PBS -M tigerfan7495@gmail.com

echo "-----------------------------------------------------"
echo "Date: $(date)                     Host:$(hostname)"
echo "-----------------------------------------------------"
#copy segmen result files from storage node
DATAHOST="nfs001"
DESTHOST="nfs004"
input_file="images_part01"
LOCALHOME="/data1/bwang"
LOCALDIR_RESULTS=$LOCALHOME/results
LOCALDIR_COMPOSITE_RESULTS=$LOCALHOME/composite_results
DATADIR="/data/shared/tcga_analysis/seer_data/results"
DESTDIR="/data/shared/bwang/composite_results"
master_csv_file_path="/data/shared/tcga_analysis/seer_data/analysis_list.csv"
IFS=$'\n' read -d '' -r -a caseid_list < $LOCALHOME/$input_file
master_csv_file=$LOCALHOME/analysis_list.csv
if [ ! -f $master_csv_file ]; then
    echo "Master CSV File not found!"
    scp $DATAHOST:$master_csv_file_path $LOCALHOME/analysis_list.csv
fi

for case_id in "${caseid_list[@]}"
do  
  prefix_str=`grep $case_id  $master_csv_file | awk -F ',' '{print $2}'`;  
  prefix_array=($prefix_str)  
  tLen=${#prefix_array[@]} 
  for (( i=0; i<${tLen}; i++ ));
  do
    prefix=${prefix_array[$i]}    
    local_folder=$LOCALDIR_RESULTS/$case_id/$prefix
    if [ ! -d "$local_folder" ]; then  
      echo "Folder $local_folder is not found, then create it!"     
      mkdir -p $local_folder
    fi    
    remote_folder=$DATAHOST:$DATADIR/$case_id/$prefix
    #echo $remote_folder
    json_remote_files=$remote_folder/*.json    
    csv_remote_files=$remote_folder/*features.csv
    #echo scp $json_remote_files $local_folder
    #echo scp $csv_remote_files $local_folder
    scp $json_remote_files $local_folder
    scp $csv_remote_files $local_folder
  done  
done

cd $PBS_O_WORKDIR
python composite_dataset.py  $(hostname) $input_file 

#sync composite_results to storage node
echo ssh $DESTHOST mkdir -p $DESTDIR
ssh $DESTHOST mkdir -p $DESTDIR

echo rsync -avr  $LOCALDIR/ $DESTHOST:$DESTDIR/
rsync -av -r $LOCALDIR_COMPOSITE_RESULTS/ $DESTHOST:$DESTDIR/

rm -rf $LOCALDIR_RESULTS
rm -rf $LOCALDIR_COMPOSITE_RESULTS

echo "-----------------------------------------------------"
echo "Date: $(date)"
echo "-----------------------------------------------------"

